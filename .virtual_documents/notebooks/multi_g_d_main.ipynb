








import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Implementation of explicit dtype hinting
dtype_map = {'hours_studied': 'float32', 'previous_scores': 'float32',
             'extra_activities': 'category', 'sleep_hours': 'float32',
             'sample_question': 'float32', 'performance_index': 'float32'}


column_names = ['hours_studied', 'previous_scores', 'extra_activities',
                'sleep_hours', 'sample_question', 'performance_index']

# While the Uber_Fares dataset is massive, I am willing to sacrifice performance to improve accuracy
sp_df = pd.read_csv('../data/dataset_a_s_e_p/Student_Performance/Student_Performance.csv', names=column_names, header=0, dtype=dtype_map)

# Data exploration
print("Print first 20 rows of each column:\n", sp_df.head(20))

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(sp_df.describe())





# Standarize values
sp_df['extra_activities'] = (
    sp_df['extra_activities']
        .str.strip()
        .str.lower()
)

# Map 'yes' to 1, 'no' to 0
sp_df['extra_activities'] = sp_df['extra_activities'].map({'yes':1,
                            'no':0}).astype(np.float32)

print(sp_df.head(20))

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(sp_df.describe())








numeric_columns = ['hours_studied', 'previous_scores', 'sleep_hours', 
                      'sample_question'] # Purposely skips 'extra_activities' as it is already scaled. 
                                        # 'performance_index' isn't scaled as it's the target column.

# Mean/STD calculation
mean = sp_df[numeric_columns].mean()
std = sp_df[numeric_columns].std()

# Standardization of each column
sp_df[numeric_columns] = ((sp_df[numeric_columns] - mean) / std)





# 80% split index
split_index = int(len(sp_df) * 0.8)

# Split of dataframe
train_sp_df = sp_df.iloc[:split_index]
test_sp_df = sp_df.iloc[split_index:]

# Size verification
print(f'Size of Training Set: {len(train_sp_df)}')
print(f'Size of Test Set: {len(test_sp_df)}')


# Data exploration
print("Print first 20 rows of each column:\n", train_sp_df.head(20))

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(train_sp_df.describe())

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(test_sp_df.describe())





# Check for missing data
print("\n Null values: \n", train_sp_df.isnull().sum())

# 100% validity verified
train_sp_df_clean = train_sp_df.copy()


# Data exploration/prep of test data
print("\n Null values: \n", test_sp_df.isnull().sum()) # Does not verifies 100% data validity.

# 100% validity verified
test_sp_df_clean = test_sp_df.copy()














# Feature columns to ensure only features are normalized
feature_columns = ['hours_studied', 'previous_scores', 'sleep_hours', 'sample_question', 'extra_activities']

# If algorithm performance is not adequeate 'passenger_count' will be removed

print(feature_columns)








# Prediction function/formula
def predict(X, b, w):
    # X: shape (n_samples, n_features)
    # w: shape (n_features,)
    # b: scalar
    return X.dot(w) + b


def rmse_mae_r2(X, b, w, y_actual):
    w = w.ravel()              # shape enforcement
    y_hat = predict(X, b, w)
    rmse  = np.sqrt(np.mean((y_actual - y_hat)**2))
    mae   = np.mean(np.abs(y_actual - y_hat))
    r2    = 1 - np.sum((y_actual - y_hat)**2) / np.sum((y_actual - y_actual.mean())**2)
    print(f" RMSE {rmse:,.4f} | MAE {mae:,.4f} | R² {r2:.4f}")











# Set-up for learning model
# Example: create random (dummy) data for demo purposes
np.random.seed(42)          # .seed() ensures that the random numbers generated are the same each time the program is run
n_samples = 100
n_features = 5
demo_X = np.random.randn(n_samples, n_features)    # Features matrix
weights_true = np.array([1.5, -2.0, 1.0, 1.5, 2])            # True weights (for testing)
demo_y = demo_X @ weights_true + 0.5             # y = Xw + b, with true bias 0.5


# Verify shape of X
print(demo_X.shape)


def g_d_func(X, y, b_init=0.0, learning_rate=0.05, iterations=1000, w_init=None, i_displayed=100):
    # Make sure w matches the number of features
    X = np.asarray(X, dtype=np.float32)               
    y = np.asarray(y, dtype=np.float32)               
    n_features = X.shape[1]

    if w_init is None:
        w = np.zeros(n_features, dtype=np.float32)
    else:
        w = np.asarray(w_init, dtype=np.float32)
        assert w.shape == (n_features,), "w_init length must equal n_features"
    
    # Ensures b is able to move around the horizontal plane
    b = float(b_init)
    total_cost = []

    m = len(y)
    for i in range(iterations):
        y_hat = X.dot(w) + b
        error = y_hat - y

        # Compute gradients
        grad_w = (2 / len(X)) * X.T.dot(error)
        grad_b = (2 / len(X)) * error.sum() # Scalar

        # Update parameters
        w -= learning_rate * grad_w
        b -= learning_rate * grad_b

        # Track cost
        mse = (error ** 2).mean()
        total_cost.append(mse)

        if i % i_displayed == 0:
            print(f"Iter {i:5d}: MSE={mse:.4f}")
    
    print("Final Weights:", w)
    print("Final Bias:", b)
    print("Final Cost:", mse)

    return b, w, total_cost


demo_b, demo_w, demo_total_cost = g_d_func(X=demo_X, y=demo_y, learning_rate=0.5, iterations=5, i_displayed=1)








sns.lineplot(demo_total_cost)
plt.title('Demo: Cost Over Iterations')
plt.xlabel('Iterations')
plt.ylabel('Cost')


# Generation of Key Algorithm Performance Metrics
rmse_mae_r2(demo_X, demo_b, demo_w, demo_y)

















train_feature_data = train_sp_df_clean[feature_columns]
train_target_data = train_sp_df_clean['performance_index']

train_X = train_feature_data.to_numpy()
train_y = train_target_data.to_numpy()



test_feature_data = train_sp_df_clean[feature_columns]
test_target_data = train_sp_df_clean['performance_index']

test_X = test_feature_data.to_numpy()
test_y = test_target_data.to_numpy()


train_b, train_w, train_total_cost = g_d_func(X=train_X, y=train_y, b_init=19.2, learning_rate=0.699, iterations=60, i_displayed=10)








sns.lineplot(training_total_cost)
plt.title('Training Data: Cost Over Iterations')
plt.xlabel('Iterations')
plt.ylabel('Cost')





# Generation of Key Algorithm Performance Metrics
rmse_mae_r2(train_X, train_b, train_w, train_y)














# In order to implement LASSO Regression from scratch, I will be creating a new function that is specifically designed around the advancement.

def g_d_lasso(X, y, learning_rate=0.01, b_init=0.0, lambda_=0.1, iterations=1000):
    n_samples, n_features = X.shape
    w = np.random.randn(n_features) * .000005
    cost_history = []
    b = b_init
    
    for i_1 in range(iterations):
        y_hat = X.dot(w) + b
        residual = y - y_hat

        # Gradients
        dw = (-1/n_samples) * X.T.dot(residual) + lambda_ * np.sign(w)
        db = (-1/n_samples) * np.sum(residual)

        # Update rules
        w -= learning_rate * dw
        b -= learning_rate * db

        # Calculate cost
        cost = (1 / (2 * n_samples) * np.sum(residual ** 2) + lambda_ * np.sum(np.abs(w)))
        cost_history.append(cost)
        
        # Print progress every 10 iterations
        if i_1 % 10 == 0:
            print(f"Iteration: {i_1}: Cost={cost:.4f}")
    
    print("Final Weights:", w)
    print("Final Bias:", b)
    print("Final Cost:", cost)

    return b, w, cost_history


# Calling lasso_batch_gradient_descent with training data
train_b_lasso, train_w_lasso, train_cost_history_lasso = g_d_lasso(
    train_X, train_y, learning_rate=0.999999999, b_init=19.2, lambda_=.00000000095, iterations=50)





sns.lineplot(training_cost_history_lasso)
plt.title('Training Data: Cost Over Iterations')
plt.xlabel('Iterations')
plt.ylabel('Cost')


# Generation of Key Algorithm Performance Metrics
rmse_mae_r2(train_X, train_b, train_w, train_y)





residuals = y_test - y_hat
std_residual = residuals / np.std(residuals)

plt.figure(figsize=(8, 5))
plt.scatter(y_test, std_residual, alpha=0.4)
plt.axhline(0, color="k")
plt.axhline(2, color="r", linestyle="--")
plt.axhline(-2, color="r", linestyle="--")
plt.xlabel("True y")
plt.ylabel("Standardized residual")
plt.title("Standardized Residual Plot — Test Set")
plt.show()

# Histogram
plt.hist(residuals, bins=30)
plt.xlabel("Residual")
plt.ylabel("Frequency")
plt.title("Histogram of Residuals")
plt.show()









