








import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# I chose to port data into the project via excel to ensure data preservation
pm_test_df = pd.read_excel('../data/dataset_a_s_e_p/PM_test.xlsx')

# Data exploration
print("Print first 20 rows of each column:\n", pm_test_df.head(20))

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_test_df.describe())





# Check for missing data
print("\n Null values: \n", pm_test_df.isnull().sum()) # Verifies 100% data validity.


# Generalized NA drop is not required because the data card indicates that 100% of the data is valid
# pm_test_df_clean = pm_test_df.dropna()
pm_test_df_clean = pm_test_df.copy()

# Confirmation of null removal
print("\n Null values: \n", pm_test_df_clean.isnull().sum())

# Check for constants
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_test_df_clean.describe())








# Feature columns to ensure only features are normalized
feature_columns = [f's{i}' for i in range(1, 22) if i not in [1, 6, 10, 16, 18, 19]]

print(feature_columns)

# Pre-data "normalization" check
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_test_df_clean.describe())

# Mean/STD calculation of pm_test
mean = pm_test_df_clean[feature_columns].mean()
std = pm_test_df_clean[feature_columns].std()

# Standardization of each column
pm_test_df_clean.loc[:, feature_columns] = (
    pm_test_df_clean[feature_columns] - mean) / std


# Scaling confirmation
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_test_df_clean.describe())











# Prediction function/formula
def predict(X, w, b):
    # X: shape (n_samples, n_features)
    # w: shape (n_features,)
    # b: scalar
    return np.dot(X, w) + b





# MSE cost function implementation
def cost(y_actual, y_predict):
    return np.mean((y_actual - y_predict) ** 2)








# Set-up for learning model
# Example: create random (dummy) data for demo purposes
np.random.seed(42)          # .seed() ensures that the random numbers generated are the same each time the program is run
n_samples = 100
n_features = 3
X_demo = np.random.randn(n_samples, n_features)    # Features matrix
weights_true = np.array([1.5, -2.0, 1.0])            # True weights (for testing)
y_demo = X_demo @ weights_true + 0.5             # y = Xw + b, with true bias 0.5


# Verify shape of X
print(X_demo.shape)


# Function creation for Multi-variate Gradient Descent
def g_d_funct(X, y, learning_rate, b, iterations):
    n_features = X.shape[1] # Obtains length of training set
    w = np.zeros(n_features)
    total_cost = []
    
    for i_1 in range(iterations):
        # Predict
        y_predict = predict(X, w, b)
        # Compute cost
        cost_per_it = cost(y, y_predict)
        total_cost.append(cost_per_it)
    
        # Compute gradients
        # Gradient w.r.t w: -2/n * X.T @ (y_true - y_pred)
        # Gradient w.r.t b: -2/n * sum(y_true - y_pred)
        n = X.shape[0]
        dw = -2/n * np.dot(X.T, (y - y_predict))
        db = -2/n * np.sum(y - y_predict)
    
        # Update weights
        w -= learning_rate * dw
        b -= learning_rate * db
    
        # Print progress every 10 epochs (optional)
        if i_1 % 10 == 0:
            print(f"Iteration: {i_1}: cost={cost_per_it:.4f}")
    
    print("Final weights:", w)
    print("Final bias:", b)
    return b, w, total_cost


demo_b, demo_w, demo_total_cost = g_d_funct(X=X_demo, y=y_demo, b=0., learning_rate=0.01, iterations=410)





sns.lineplot(demo_total_cost)
plt.title('Demo: Cost Over Iterations')
plt.xlabel('Iterations')
plt.ylabel('Cost')











# Load training set
pm_train_df = pd.read_excel('../data/dataset_a_s_e_p/PM_train.xlsx')

# Data exploration
print("Print first 20 rows of each column:\n", pm_train_df.head(20))

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_train_df.describe())


# Load truth set
pm_target_df = pd.read_excel('../data/dataset_a_s_e_p/PM_truth.xlsx')

# Data exploration
print("Print first 20 rows of each column:\n", pm_target_df.head(20))

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_target_df.describe())

















# NA drop not required
pm_train_df_clean = pm_train_df.copy()

# Feature columns to ensure only features are normalized
train_feature_columns = [f's{i}' for i in range(2, 22) if i not in [5, 6, 10, 16, 18, 19]] 

print(train_feature_columns)

# Pre-data "normalization" check
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_train_df_clean.describe())

# Mean/STD calculation of pm_test
mean = pm_train_df_clean[train_feature_columns].mean()
std = pm_train_df_clean[train_feature_columns].std()

# Standardization of each column
pm_train_df_clean[train_feature_columns] = pm_train_df_clean[train_feature_columns].astype(float)
pm_train_df_clean.loc[:, train_feature_columns] = (pm_train_df_clean[train_feature_columns] - mean) / std


# Scaling confirmation
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_train_df_clean.describe())








# Data prep for truth set
# No NA drop or Z-score normalization required

merged_train_df = pd.merge(pm_train_df_clean, pm_target_df, on='id')
merged_train_df['RUL'] = merged_train_df['more'] - merged_train_df['cycle'] # RUL (Remaining Useful Life) 

features_data = merged_train_df[train_feature_columns]

target_data = merged_train_df['more'] # 'more' is name of the column which houses the cycle number of when each engine failed





X_train = features_data.to_numpy()
y_train = target_data.to_numpy()


training_b, training_w, training_total_cost = g_d_funct(X=X_train, y=y_train, b=75.15, learning_rate=0.05, iterations=2000)











sns.lineplot(training_total_cost)
plt.title('Training Data: Cost Over Iterations')
plt.xlabel('Iterations')
plt.ylabel('Cost')





# Load truth set
pm_test_df = pd.read_excel('../data/dataset_a_s_e_p/PM_test.xlsx')

# Data exploration
print("Print first 20 rows of each column:\n", pm_test_df.head(20))

print("\nData description:\n")
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_test_df.describe())











# NA drop not required
pm_test_df_clean = pm_test_df.copy()

# Feature columns to ensure only features are normalized
test_feature_columns = [f's{i}' for i in range(2, 22) if i not in [5, 6, 10, 16, 18, 19]] 
# Despite s5 having an std greater than 0, it still needs to be dropped to avoid an alignment error.

print(test_feature_columns)

# Pre-data "normalization" check
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_test_df_clean.describe())

# Mean/STD calculation of pm_test
mean = pm_test_df_clean[test_feature_columns].mean()
std = pm_test_df_clean[test_feature_columns].std()

# Standardization of each column
pm_test_df_clean.loc[:, test_feature_columns] = (
    pm_test_df_clean[test_feature_columns] - mean) / std


# Scaling confirmation
with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_test_df_clean.describe())








# Creation of X_test
test_features_data = pm_test_df_clean[test_feature_columns]

# Merge of truth and test tables

merged_test_df = pd.merge(pm_test_df_clean, pm_target_df, on='id')
merged_test_df['RUL'] = merged_test_df['more'] - merged_test_df['cycle'] # RUL (Remaining Useful Life) 

test_features_data = merged_test_df[test_feature_columns]
test_target_data = merged_test_df['more'] # 'more' is name of the column which houses the cycle number of when each engine failed

# Conversion to Numpy Array
X_test = test_features_data.to_numpy()
y_test = test_target_data.to_numpy()





# Use predict function to test final 'w' and 'b' values
y_pred_test = predict(X_test, training_w, training_b)

# Calculate MSE (Mean Squared Error)
mse = np.mean((y_test - y_pred_test) ** 2)

# Calculate RMSE (Root Mean Squared Error)
rmse = np.sqrt(mse) # Puts MSE back into the root unit. Increases readablility.

print(f'Test RMSE: {rmse:.4f}')





with pd.option_context('display.max_columns', None, 'display.max_rows', None):
    print(pm_target_df.describe())














# In order to implement LASSO Regression from scratch, I will be creating a new function that is specifically designed around the advancement.

def lasso_batch_gradient_descent(X, y, learning_rate=0.01, b=0.0, lambda_=0.1, iterations=1000):
    n_samples, n_features = X.shape
    w = np.random.randn(n_features) * 0.01
    cost_history = []
    
    
    for i_1 in range(iterations):
        y_pred = X.dot(w) + b
        residual = y - y_pred

        # Gradients
        dw = (-1/n_samples) * X.T.dot(residual) + lambda_ * np.sign(w)
        db = (-1/n_samples) * np.sum(residual)

        # Update rules
        w -= learning_rate * dw
        b -= learning_rate * db

        # Calculate cost
        cost = (1 / (2 * n_samples) * np.sum(residual ** 2) + lambda_ * np.sum(np.abs(w)))
        cost_history.append(cost)
        
        # Print progress every 10 iterations
        if i_1 % 10 == 0:
            print(f"Iteration: {i_1}: Cost={cost:.4f}")
    
    print("Final Weights:", w)
    print("Final Bias:", b)
    print("Final Cost:", cost)

    return w, b, cost_history


# Calling lasso_batch_gradient_descent with training data
training_w_lasso, training_b_lasso, training_cost_history_lasso = lasso_batch_gradient_descent(
    X_train, y_train, learning_rate=0.00955, b=75.15, lambda_=.000000005, iterations=5000)





sns.lineplot(training_cost_history_lasso)
plt.title('Training Data: Cost Over Iterations')
plt.xlabel('Iterations')
plt.ylabel('Cost')


# Use predict function to test final 'w' and 'b' values
y_pred_test = predict(X_train, training_w_lasso, training_b_lasso)

# Calculate MSE (Mean Squared Error)
mse = np.mean((y_pred_train - y_train) ** 2)

# Calculate RMSE (Root Mean Squared Error)
rmse = np.sqrt(mse) # Puts MSE back into the root unit. Increases readablility.

print(f'Test RMSE: {rmse:.4f}')






